{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7171, 7)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"naver_food_info.csv\")\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6710, 7)\n"
     ]
    }
   ],
   "source": [
    "# 행이 동일한 중복된 행 찾기(크롤링 시간에 따라 영업시간 다름 이슈로 id 기준 중복 제거하기로 함)\n",
    "# print(len(df[df.duplicated()]))\n",
    "# print(df[df.duplicated()])\n",
    "\n",
    "# 눈으로 확인하고 싶어서~\n",
    "# duplicates = df[df.duplicated()]\n",
    "# duplicates.to_csv(\"duplicates.csv\", index=False)\n",
    "\n",
    "# 중복 데이터 제거\n",
    "# df = df.drop_duplicates()\n",
    "# print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "575\n",
      "(6596, 7)\n"
     ]
    }
   ],
   "source": [
    "# 중복된 id를 가진 행들 찾기\n",
    "duplicates = df[df.duplicated(subset=[\"id\"], keep=\"first\")]\n",
    "# 개수 출력\n",
    "print(len(duplicates))\n",
    "# id 중복 행 제거\n",
    "df = df.drop_duplicates(subset=['id'], keep='first')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "누락된 ID: [2992, 2993, 2994, 2995, 2996, 2997, 2998, 2999, 3000]\n"
     ]
    }
   ],
   "source": [
    "# ID 범위\n",
    "expected_ids = set(range(1, 6606))  # 1부터 6605까지의 ID\n",
    "\n",
    "# 실제로 있는 ID\n",
    "actual_ids = set(df['id'])\n",
    "\n",
    "# 없는 ID 찾기\n",
    "missing_ids = sorted(expected_ids - actual_ids)\n",
    "\n",
    "print(\"누락된 ID:\", missing_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 누락된 id 다시 크롤링해서 집어넣음\n",
    "df.to_csv(\"naver_food_info_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6605, 7)\n"
     ]
    }
   ],
   "source": [
    "# 중복 제거를 위해 다시 읽기\n",
    "df = pd.read_csv(\"naver_food_info_2.csv\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id domain store_name category  rating                  address  \\\n",
      "0        1  naver        NaN      NaN     NaN                      NaN   \n",
      "1        2  naver        NaN      NaN     NaN                      NaN   \n",
      "2        3  naver        NaN      NaN     NaN                      NaN   \n",
      "3        4  naver        NaN      NaN     NaN                      NaN   \n",
      "4        5  naver        NaN      NaN     NaN                      NaN   \n",
      "...    ...    ...        ...      ...     ...                      ...   \n",
      "6600  6601  naver       고흥식당       한식     4.4           서울 종로구 종로34길 4   \n",
      "6601  6602  naver        NaN      NaN     NaN                      NaN   \n",
      "6602  6603  naver        NaN      NaN     NaN                      NaN   \n",
      "6603  6604  naver        NaN      NaN     NaN                      NaN   \n",
      "6604  6605  naver   콘크리트 팔레트   카페,디저트     NaN  서울 종로구 대학로 125 콘크리트 팔레트   \n",
      "\n",
      "                                         business_hours  \n",
      "0                                                   NaN  \n",
      "1                                                   NaN  \n",
      "2                                                   NaN  \n",
      "3                                                   NaN  \n",
      "4                                                   NaN  \n",
      "...                                                 ...  \n",
      "6600                                                NaN  \n",
      "6601                                                NaN  \n",
      "6602                                                NaN  \n",
      "6603                                                NaN  \n",
      "6604   수\\n10:00 - 22:00\\n21:30 라스트오더 목\\n10:00 - 22:0...  \n",
      "\n",
      "[6605 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# 빈 문자열이나 None을 NaN으로 변경\n",
    "df.replace({\"\": np.nan}, inplace=True)\n",
    "# 결과 확인\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id domain   store_name  category  rating address business_hours\n",
      "1705  1706  naver  신선식탁 대학로 본점  다이어트,샐러드    4.54     NaN            NaN\n",
      "1919  1920  naver  원조 순희네육회빈대떡     전,빈대떡    4.38     NaN            NaN\n",
      "2091  2092  naver     종로 은행나무집   육류,고기요리    4.37     NaN            NaN\n",
      "4051\n"
     ]
    }
   ],
   "source": [
    "# 중복된 id를 가진 행들 찾기\n",
    "# duplicates = df[df.duplicated(subset=[\"id\"], keep=\"first\")]\n",
    "# 개수 출력 -> 0\n",
    "# print(len(duplicates))\n",
    "\n",
    "# 데이터 빈 값이 아니고, store_name 기준으로 중복된 데이터\n",
    "# duplicates = df[df[\"store_name\"].notna() & df.duplicated(subset=[\"store_name\"], keep=False)]\n",
    "# 개수 출력 -> 2710(.......?)\n",
    "# print(len(duplicates))\n",
    "# duplicates.to_csv(\"duplicates.csv\", index=False)\n",
    "\n",
    "# 이름은 같지만 주소는 다른 동명 가게들도 있음 확인 -> 이름과 주소가 같은 데이터 행 값 제거\n",
    "# duplicates = df[df[\"store_name\"].notna() & (df[\"store_name\"] != \"\")].loc[df.duplicated(subset=[\"store_name\", \"address\"], keep=\"first\")]\n",
    "# print(len(duplicates))\n",
    "# 중복 행에서 id와 domain 컬럼을 제외한 나머지 컬럼을 NaN으로 설정\n",
    "# columns_to_nan = [col for col in df.columns if col not in [\"id\", \"domain\"]]\n",
    "# df.loc[duplicates.index, columns_to_nan] = np.nan\n",
    "# store_name 컬럼에서 값이 있는 행의 개수 세기\n",
    "# store_name_count = df[df[\"store_name\"].notna() & (df[\"store_name\"] != \"\")].shape[0]\n",
    "# print(store_name_count)\n",
    "\n",
    "# 이름, 카테고리, 별점 똑같은데 주소가 없어서 필터링 안된 거 찾기\n",
    "# duplicates = df[df[\"store_name\"].notna() & (df[\"store_name\"] != \"\")].duplicated(subset=[\"store_name\", \"address\"], keep=False)\n",
    "duplicates = df[df[\"store_name\"].notna() & (df[\"store_name\"] != \"\") & df[\"address\"].isna()].loc[df.duplicated(subset=[\"store_name\", \"category\", \"rating\"], keep=\"first\")]\n",
    "print(duplicates)\n",
    "# 중복 행에서 id와 domain 컬럼을 제외한 나머지 컬럼을 NaN으로 설정\n",
    "columns_to_nan = [col for col in df.columns if col not in [\"id\", \"domain\"]]\n",
    "df.loc[duplicates.index, columns_to_nan] = np.nan\n",
    "# store_name 컬럼에서 값이 있는 행의 개수 세기\n",
    "store_name_count = df[df[\"store_name\"].notna() & (df[\"store_name\"] != \"\")].shape[0]\n",
    "print(store_name_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>domain</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>address</th>\n",
       "      <th>business_hours</th>\n",
       "      <th>price_per_one</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>naver</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>naver</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>naver</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>naver</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>naver</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6600</th>\n",
       "      <td>6601</td>\n",
       "      <td>naver</td>\n",
       "      <td>고흥식당</td>\n",
       "      <td>한식</td>\n",
       "      <td>4.4</td>\n",
       "      <td>서울 종로구 종로34길 4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6601</th>\n",
       "      <td>6602</td>\n",
       "      <td>naver</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6602</th>\n",
       "      <td>6603</td>\n",
       "      <td>naver</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6603</th>\n",
       "      <td>6604</td>\n",
       "      <td>naver</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6604</th>\n",
       "      <td>6605</td>\n",
       "      <td>naver</td>\n",
       "      <td>콘크리트 팔레트</td>\n",
       "      <td>카페,디저트</td>\n",
       "      <td>NaN</td>\n",
       "      <td>서울 종로구 대학로 125 콘크리트 팔레트</td>\n",
       "      <td>수\\n10:00 - 22:00\\n21:30 라스트오더 목\\n10:00 - 22:0...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6605 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id domain      name category  rating                  address  \\\n",
       "0        1  naver       NaN      NaN     NaN                      NaN   \n",
       "1        2  naver       NaN      NaN     NaN                      NaN   \n",
       "2        3  naver       NaN      NaN     NaN                      NaN   \n",
       "3        4  naver       NaN      NaN     NaN                      NaN   \n",
       "4        5  naver       NaN      NaN     NaN                      NaN   \n",
       "...    ...    ...       ...      ...     ...                      ...   \n",
       "6600  6601  naver      고흥식당       한식     4.4           서울 종로구 종로34길 4   \n",
       "6601  6602  naver       NaN      NaN     NaN                      NaN   \n",
       "6602  6603  naver       NaN      NaN     NaN                      NaN   \n",
       "6603  6604  naver       NaN      NaN     NaN                      NaN   \n",
       "6604  6605  naver  콘크리트 팔레트   카페,디저트     NaN  서울 종로구 대학로 125 콘크리트 팔레트   \n",
       "\n",
       "                                         business_hours  price_per_one  \n",
       "0                                                   NaN            NaN  \n",
       "1                                                   NaN            NaN  \n",
       "2                                                   NaN            NaN  \n",
       "3                                                   NaN            NaN  \n",
       "4                                                   NaN            NaN  \n",
       "...                                                 ...            ...  \n",
       "6600                                                NaN            NaN  \n",
       "6601                                                NaN            NaN  \n",
       "6602                                                NaN            NaN  \n",
       "6603                                                NaN            NaN  \n",
       "6604   수\\n10:00 - 22:00\\n21:30 라스트오더 목\\n10:00 - 22:0...            NaN  \n",
       "\n",
       "[6605 rows x 8 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 컬럼명 변경\n",
    "df = df.rename(columns={\"store_name\": \"name\"})\n",
    "# 컬럼 추가\n",
    "df['price_per_one'] = np.nan\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4051 데이터 저장저장!!\n",
    "df.to_csv(\"naver_food_info_3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4051\n",
      "4051\n"
     ]
    }
   ],
   "source": [
    "# 다시 읽기\n",
    "df = pd.read_csv(\"naver_food_info_3.csv\")\n",
    "print(sum(df[\"name\"].notna()))\n",
    "print(sum(df[\"category\"].notna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "[nan '바(BAR)' '생선회' '피자' '백숙,삼계탕' '분식' '카페' '브런치카페' '한식' '카페,디저트' '패션'\n",
      " '육류,고기요리' '국밥' '우동,소바' '소고기구이' '종합분식' '장어,먹장어요리' '일식당' '양식' '이탈리아음식'\n",
      " '한정식' '햄버거' '베이커리' '딤섬,중식만두' '치킨,닭강정' '순대,순댓국' '후렌치후라이' '이자카야' '요리주점'\n",
      " '맥주,호프' '서점' '포장마차' '아이스크림' '감자탕' '중식당' '일본식라면' '돈가스' '스파게티,파스타전문'\n",
      " '일식튀김,꼬치' '베트남음식' '두부요리' '전복요리' '돼지고기구이' '와인' '닭요리' '태국음식' '다이어트,샐러드'\n",
      " '갤러리,화랑' '술집' '프랑스음식' '칼국수,만두' '떡볶이' '카레' '곰탕,설렁탕' '브런치' '주류' '국수' '공방'\n",
      " '아시아음식' '퓨전음식' '양꼬치' '오징어요리' '바나프레소' '독일음식' '해물,생선요리' '과일,주스전문점'\n",
      " '전통,민속주점' '보드카페' '북카페' '라면' '샌드위치' '차' '패밀리레스토랑' '멕시코,남미음식' '만두'\n",
      " '테이크아웃커피' '매운탕,해물탕' '인테리어소품' '오뎅,꼬치' '도시락,컵밥' '이북음식' '주류제조' '마라탕'\n",
      " '곱창,막창,양' '해장국' '추어탕' '덮밥' '인도음식' '죽' '장소대여' '김밥' '초밥,롤' '꽃집,꽃배달' '농수산물'\n",
      " '한식뷔페' '푸드코트' '호텔' '샤브샤브' '토스트' '테마카페' '한방카페' '찌개,전골' '냉면' '공연장' '중개업'\n",
      " '도서,음반,문구' '섬유,의류' '족발,보쌈' '복합문화공간' '72420' '도시락,조리식품제조' '라이브카페' '생선구이'\n",
      " '자동판매기' '조개요리' '막국수' '낙지요리' '슈퍼,마트' '닭갈비' '사주카페' '모텔' '비빔밥' '전통숙소' '전시관'\n",
      " '차,커피' '전,빈대떡' '키즈카페,실내놀이터' '떡카페' '정육식당' '와플' '건강기능보조식품' '블루보틀' '미술관'\n",
      " '터키음식' '반찬가게' '기업' '여성의류' '호떡' '종합패션' '백반,가정식' '예식장' '볼링장' '문화원' '기타숙박업'\n",
      " '주꾸미요리' '사철,영양탕' '전시,행사대행' '만화방' '스테이크,립' '아귀찜,해물찜' '양갈비' '찜닭' '한복'\n",
      " '미술,공예품' '신의주부대찌개' '핫도그' '3급' '교육원,교육센터' '패션잡화' '뷔페' '사찰음식' '닭볶음탕' '양말'\n",
      " '독립서점' '복어요리' '여행사' '갤러리카페' '식료품' '닭발' '요리교육' '가구,인테리어' '빙수' '초콜릿전문점'\n",
      " '스페인음식' '케이크전문' '보세의류' '향토음식' '보리밥' '유흥주점' '굴요리' '운세,사주' '쌈밥' '오리요리'\n",
      " '소고기' '룸카페' '화장품,향수' '다방' '야식' '밀키트' '인테리어디자인' '갈비탕' '채식,샐러드뷔페' '기업,빌딩'\n",
      " '스터디카페' '도자기' '바닷가재요리' '두부제조' '한복대여' '음식점' '도넛']\n"
     ]
    }
   ],
   "source": [
    "# 연관 없는 카테고리 삭제\n",
    "# 카테고리 종류 확인\n",
    "print(len(df[\"category\"].unique()))\n",
    "print(df[\"category\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n",
      "132\n",
      "3919\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 유지 리스트(음식점, 카페, 술집) = ['바(BAR)', '생선회', '피자', '백숙,삼계탕', '분식', '카페', \n",
    "# '브런치카페', '한식', '카페,디저트', '육류,고기요리', '국밥', '우동,소바', '소고기구이', '종합분식', \n",
    "# '장어,먹장어요리', '일식당', '양식', '이탈리아음식', '한정식', '햄버거', '베이커리', '딤섬,중식만두',\n",
    "# '치킨,닭강정', '순대,순댓국', '후렌치후라이', '이자카야', '요리주점', '맥주,호프', '포장마차', \n",
    "# '아이스크림', '감자탕', '중식당', '일본식라면', '돈가스', '스파게티,파스타전문', '일식튀김,꼬치', \n",
    "# '베트남음식', '두부요리', '전복요리', '돼지고기구이', '와인', '닭요리', '태국음식', '다이어트,샐러드', \n",
    "# '술집', '프랑스음식', '칼국수,만두', '떡볶이', '카레', '곰탕,설렁탕', '브런치', '국수', '아시아음식', \n",
    "# '퓨전음식', '양꼬치', '오징어요리', '바나프레소', '독일음식', '해물,생선요리', '과일,주스전문점', \n",
    "# '전통,민속주점', '라면', '샌드위치', '차', '패밀리레스토랑', '멕시코,남미음식', '만두', '테이크아웃커피',\n",
    "# '매운탕,해물탕', '오뎅,꼬치', '도시락,컵밥', '이북음식', '마라탕', '곱창,막창,양', '해장국', '추어탕', \n",
    "# '덮밥', '인도음식', '죽', '김밥', '초밥,롤', '한식뷔페', '샤브샤브', '토스트', '한방카페', \n",
    "# '찌개,전골', '냉면', '족발,보쌈', '72420', '라이브카페', '생선구이', '조개요리', '막국수', '낙지요리', \n",
    "# '슈퍼,마트', '닭갈비', '비빔밥', '차,커피', '전,빈대떡', '떡카페', '정육식당', '와플', '백반,가정식', \n",
    "# '주꾸미요리', '사철,영양탕', '블루보틀', '터키음식', '호떡', '스테이크,립', '아귀찜,해물찜', '양갈비', \n",
    "# '찜닭', '신의주부대찌개', '핫도그', '뷔페', '사찰음식', '닭볶음탕', '복어요리', '닭발', '빙수', \n",
    "# '초콜릿전문점', '스페인음식', '케이크전문', '향토음식', '보리밥', '유흥주점', '굴요리', '쌈밥', \n",
    "# '오리요리', '소고기', '룸카페', '다방', '야식', '갈비탕', '채식,샐러드뷔페', '바닷가재요리', \n",
    "# '음식점', '도넛']\n",
    "\n",
    "# 삭제할 카테고리 리스트\n",
    "exclude_categories = ['패션', '서점', '갤러리,화랑', '주류', '공방', '보드카페', '북카페', \n",
    "       '인테리어소품', '주류제조', '장소대여', '꽃집,꽃배달', '농수산물', '푸드코트', '호텔', '공연장', \n",
    "       '중개업', '도서,음반,문구', '섬유,의류', '복합문화공간', '도시락,조리식품제조', '자동판매기', \n",
    "       '사주카페', '모텔', '전통숙소', '전시관', '키즈카페,실내놀이터', '건강기능보조식품', '미술관', \n",
    "       '반찬가게', '기업', '여성의류', '종합패션', '예식장', '볼링장', '문화원', '기타숙박업', \n",
    "       '전시,행사대행', '만화방', '한복', '미술,공예품', '3급', '교육원,교육센터', '패션잡화', \n",
    "       '양말', '독립서점', '여행사', '갤러리카페', '식료품', '요리교육', '가구,인테리어', '보세의류', \n",
    "       '운세,사주', '화장품,향수', '밀키트', '인테리어디자인', '기업,빌딩', '스터디카페', '도자기',\n",
    "       '두부제조', '한복대여', '테마카페']\n",
    "print(len(exclude_categories))\n",
    "# 특정 카테고리를 포함하는 행을 찾고, 해당 행의 나머지 컬럼을 NaN으로 설정 -> 4051-132 = 3919\n",
    "print(len(df.loc[df['category'].isin(exclude_categories)]))\n",
    "df.loc[df['category'].isin(exclude_categories), ['name', 'category', 'rating', 'address', 'business_hours', 'price_per_one']] = np.nan\n",
    "print(sum(df[\"name\"].notna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id domain name  main_category category  rating address business_hours  \\\n",
      "0   1  naver  NaN            NaN      NaN     NaN     NaN            NaN   \n",
      "1   2  naver  NaN            NaN      NaN     NaN     NaN            NaN   \n",
      "2   3  naver  NaN            NaN      NaN     NaN     NaN            NaN   \n",
      "3   4  naver  NaN            NaN      NaN     NaN     NaN            NaN   \n",
      "4   5  naver  NaN            NaN      NaN     NaN     NaN            NaN   \n",
      "\n",
      "   price_per_one  \n",
      "0            NaN  \n",
      "1            NaN  \n",
      "2            NaN  \n",
      "3            NaN  \n",
      "4            NaN  \n"
     ]
    }
   ],
   "source": [
    "# 남은 카테고리 대분류 지정\n",
    "# main_category: 카페, 음식점, 주점\n",
    "\n",
    "# category 앞에 main_category 컬럼 추가\n",
    "df.insert(df.columns.get_loc('category'), 'main_category', np.nan)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n",
      "19\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# list 구성\n",
    "restaurant = ['생선회', '피자', '백숙,삼계탕', '분식', '브런치카페', '한식', '육류,고기요리', \n",
    "              '국밥', '우동,소바', '소고기구이', '종합분식', '장어,먹장어요리', '일식당', '양식', \n",
    "              '이탈리아음식', '한정식', '햄버거', '베이커리', '딤섬,중식만두', '치킨,닭강정', \n",
    "              '순대,순댓국', '후렌치후라이', '감자탕', '중식당', '일본식라면', '돈가스', \n",
    "              '스파게티,파스타전문', '일식튀김,꼬치', '베트남음식', '두부요리', '전복요리', \n",
    "              '돼지고기구이', '닭요리', '태국음식', '다이어트,샐러드', '프랑스음식', '칼국수,만두', \n",
    "              '떡볶이', '카레', '곰탕,설렁탕', '브런치', '국수', '아시아음식', '퓨전음식', \n",
    "              '양꼬치', '오징어요리', '독일음식', '해물,생선요리', '전통,민속주점', '라면', \n",
    "              '샌드위치', '패밀리레스토랑', '멕시코,남미음식', '만두', '매운탕,해물탕', '오뎅,꼬치', \n",
    "              '도시락,컵밥', '이북음식', '마라탕', '곱창,막창,양', '해장국', '추어탕', '덮밥', \n",
    "              '인도음식', '죽', '김밥', '초밥,롤', '한식뷔페', '샤브샤브', '토스트', '찌개,전골', \n",
    "              '냉면', '족발,보쌈', '72420', '생선구이', '조개요리', '막국수', '낙지요리', \n",
    "              '닭갈비', '비빔밥', '전,빈대떡', '정육식당', '백반,가정식', '주꾸미요리', \n",
    "              '사철,영양탕', '터키음식', '스테이크,립', '아귀찜,해물찜', '양갈비', '찜닭', \n",
    "              '신의주부대찌개', '핫도그', '뷔페', '사찰음식', '닭볶음탕', '복어요리', '닭발', \n",
    "              '스페인음식', '향토음식', '보리밥', '굴요리', '쌈밥', '오리요리', '소고기', '야식', \n",
    "              '갈비탕', '채식,샐러드뷔페', '바닷가재요리', '음식점']\n",
    "cafe = ['카페', '카페,디저트', '바나프레소', '차', '블루보틀', '빙수', '초콜릿전문점', '룸카페', \n",
    "        '케이크전문', '아이스크림', '과일,주스전문점', '테이크아웃커피', '한방카페', '차,커피', \n",
    "        '떡카페', '와플', '호떡', '다방', '도넛']\n",
    "pub = ['바(BAR)', '이자카야', '요리주점', '맥주,호프', '포장마차', '와인', '술집', '라이브카페', \n",
    "       '슈퍼,마트', '유흥주점']\n",
    "print(len(restaurant))\n",
    "print(len(cafe))\n",
    "print(len(pub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_main_category(category):\n",
    "    if pd.isna(category):  # category가 NaN일 경우\n",
    "        return None  # None을 반환해서 main_category도 NaN으로 설정\n",
    "    elif category in restaurant:\n",
    "        return \"음식점\"\n",
    "    elif category in cafe:\n",
    "        return \"카페\"\n",
    "    elif category in pub:\n",
    "        return \"주점\"\n",
    "    else:\n",
    "        return \"기타\"\n",
    "\n",
    "# main_category 값 설정\n",
    "df[\"main_category\"] = df[\"category\"].apply(assign_main_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [id, domain, name, main_category, category, rating, address, business_hours, price_per_one]\n",
      "Index: []\n",
      "main_category\n",
      "음식점    2801\n",
      "카페      581\n",
      "주점      537\n",
      "Name: count, dtype: int64\n",
      "3919\n"
     ]
    }
   ],
   "source": [
    "print(df[df[\"main_category\"] == \"기타\"])\n",
    "print(df[\"main_category\"].value_counts())\n",
    "print(df[\"main_category\"].notna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3919 데이터 저장저장!! 완성 및 이름 변경 -> row_data/naver_store_info.csv\n",
    "df.to_csv(\"naver_food_info_4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6605, 9)\n",
      "3919\n",
      "(98809, 2)\n",
      "95943\n",
      "3735\n"
     ]
    }
   ],
   "source": [
    "# naver_food_info_4.csv id 기반으로 리뷰데이터 매칭\n",
    "info = pd.read_csv(\"naver_food_info_4.csv\")\n",
    "print(info.shape)\n",
    "print(sum(info[\"name\"].notna()))\n",
    "# print(sum(info[\"category\"].notna()))\n",
    "# 리뷰 데이터 읽기\n",
    "reviews = pd.read_csv(\"naver_review.csv\")\n",
    "print(reviews.shape)\n",
    "print(sum(reviews[\"review\"].notna()))\n",
    "print(len(reviews[\"id\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95943, 2)\n",
      "         id                                            reviews\n",
      "0        18  혜화동 새로 오픈한 신상 피자집! 대학로 cgv 영화관람하고 왔어요. 시그니처 바질...\n",
      "1        18  JMT !!!!!!!!!! 노모어피자 하도 유행해서 먹어봤는데 왜 먹는지 알겠더라고...\n",
      "2        18  대학로에. 노모어피자가. 생기다니!!!!!! 여기 사장님이 노모어피자 초창기 운영하...\n",
      "3        18  피자가 빨리 나오고 맛있어요! 매장 안에 화장실 있어서 편리합니당. 아이랑 갔는데 ...\n",
      "4        18  새로 생겨서 가봤는데 진짜 넘 맛도링 ~~~~\\n피자는 물론이고 바질뇨끼 진짜 맛있어요!\n",
      "...     ...                                                ...\n",
      "98804  6605  오늘은 까눌레가 늦게 나오네용 ~ 🥲\\n그래서 저번이랑 똑같이 주문했다는 ~\\n커피...\n",
      "98805  6605  오~~~랜만에 대학로 ~ 👀🤟🏻✨\\n일행 기다려야 해서 잠시 카페 들어 왔는데\\n아...\n",
      "98806  6605       밤라떼 달지 않고 맛있어요! 까눌레도 겉바속쫀득 완벽해서 커피랑 꿀조합입니다:)\n",
      "98807  6605  주말 낮에 자리 여유많았어요\\n2층도 있었어요 통유리라 낮에 유리쪽은 좀 덥긴했는데...\n",
      "98808  6605  혜화 오다가며 봤던 곳이었는데, 전체가 카페였다니ㅋㅋㄱ 상상도 못했네요!\\n콘크리트...\n",
      "\n",
      "[95943 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# 리뷰 데이터 확인\n",
    "# print(reviews)\n",
    "# id 컬럼을 정수로 변환\n",
    "reviews[\"id\"] = reviews[\"id\"].astype(int)\n",
    "# 컬럼명 변경\n",
    "reviews.rename(columns={\"review\": \"reviews\"}, inplace=True)\n",
    "# print(reviews)\n",
    "# reviews 컬럼이 NaN인 행 삭제\n",
    "reviews = reviews.dropna(subset=[\"reviews\"])\n",
    "print(reviews.shape)\n",
    "print(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id domain        name  \\\n",
      "0        18  naver  노모어피자 대학로점   \n",
      "1        18  naver  노모어피자 대학로점   \n",
      "2        18  naver  노모어피자 대학로점   \n",
      "3        18  naver  노모어피자 대학로점   \n",
      "4        18  naver  노모어피자 대학로점   \n",
      "...     ...    ...         ...   \n",
      "95938  6605  naver    콘크리트 팔레트   \n",
      "95939  6605  naver    콘크리트 팔레트   \n",
      "95940  6605  naver    콘크리트 팔레트   \n",
      "95941  6605  naver    콘크리트 팔레트   \n",
      "95942  6605  naver    콘크리트 팔레트   \n",
      "\n",
      "                                                 reviews  \n",
      "0      혜화동 새로 오픈한 신상 피자집! 대학로 cgv 영화관람하고 왔어요. 시그니처 바질...  \n",
      "1      JMT !!!!!!!!!! 노모어피자 하도 유행해서 먹어봤는데 왜 먹는지 알겠더라고...  \n",
      "2      대학로에. 노모어피자가. 생기다니!!!!!! 여기 사장님이 노모어피자 초창기 운영하...  \n",
      "3      피자가 빨리 나오고 맛있어요! 매장 안에 화장실 있어서 편리합니당. 아이랑 갔는데 ...  \n",
      "4      새로 생겨서 가봤는데 진짜 넘 맛도링 ~~~~\\n피자는 물론이고 바질뇨끼 진짜 맛있어요!  \n",
      "...                                                  ...  \n",
      "95938  오늘은 까눌레가 늦게 나오네용 ~ 🥲\\n그래서 저번이랑 똑같이 주문했다는 ~\\n커피...  \n",
      "95939  오~~~랜만에 대학로 ~ 👀🤟🏻✨\\n일행 기다려야 해서 잠시 카페 들어 왔는데\\n아...  \n",
      "95940       밤라떼 달지 않고 맛있어요! 까눌레도 겉바속쫀득 완벽해서 커피랑 꿀조합입니다:)  \n",
      "95941  주말 낮에 자리 여유많았어요\\n2층도 있었어요 통유리라 낮에 유리쪽은 좀 덥긴했는데...  \n",
      "95942  혜화 오다가며 봤던 곳이었는데, 전체가 카페였다니ㅋㅋㄱ 상상도 못했네요!\\n콘크리트...  \n",
      "\n",
      "[95943 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# reviews & info -> id 기준으로 병합\n",
    "mg_reviews = reviews.merge(info[[\"id\", \"domain\", \"name\"]], on=\"id\", how=\"left\")\n",
    "# 컬럼 순서 조정 (id -> domain -> name -> reviews)\n",
    "mg_reviews = mg_reviews[[\"id\", \"domain\", \"name\", \"reviews\"]]\n",
    "print(mg_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id domain        name  \\\n",
      "0        18  naver  노모어피자 대학로점   \n",
      "1        18  naver  노모어피자 대학로점   \n",
      "2        18  naver  노모어피자 대학로점   \n",
      "3        18  naver  노모어피자 대학로점   \n",
      "4        18  naver  노모어피자 대학로점   \n",
      "...     ...    ...         ...   \n",
      "95938  6605  naver    콘크리트 팔레트   \n",
      "95939  6605  naver    콘크리트 팔레트   \n",
      "95940  6605  naver    콘크리트 팔레트   \n",
      "95941  6605  naver    콘크리트 팔레트   \n",
      "95942  6605  naver    콘크리트 팔레트   \n",
      "\n",
      "                                                 reviews  \n",
      "0      혜화동 새로 오픈한 신상 피자집! 대학로 cgv 영화관람하고 왔어요. 시그니처 바질...  \n",
      "1      JMT !!!!!!!!!! 노모어피자 하도 유행해서 먹어봤는데 왜 먹는지 알겠더라고...  \n",
      "2      대학로에. 노모어피자가. 생기다니!!!!!! 여기 사장님이 노모어피자 초창기 운영하...  \n",
      "3      피자가 빨리 나오고 맛있어요! 매장 안에 화장실 있어서 편리합니당. 아이랑 갔는데 ...  \n",
      "4      새로 생겨서 가봤는데 진짜 넘 맛도링 ~~~~\\n피자는 물론이고 바질뇨끼 진짜 맛있어요!  \n",
      "...                                                  ...  \n",
      "95938  오늘은 까눌레가 늦게 나오네용 ~ 🥲\\n그래서 저번이랑 똑같이 주문했다는 ~\\n커피...  \n",
      "95939  오~~~랜만에 대학로 ~ 👀🤟🏻✨\\n일행 기다려야 해서 잠시 카페 들어 왔는데\\n아...  \n",
      "95940       밤라떼 달지 않고 맛있어요! 까눌레도 겉바속쫀득 완벽해서 커피랑 꿀조합입니다:)  \n",
      "95941  주말 낮에 자리 여유많았어요\\n2층도 있었어요 통유리라 낮에 유리쪽은 좀 덥긴했는데...  \n",
      "95942  혜화 오다가며 봤던 곳이었는데, 전체가 카페였다니ㅋㅋㄱ 상상도 못했네요!\\n콘크리트...  \n",
      "\n",
      "[91598 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# info에 name 컬럼이 존재하는 경우에만 reviews 데이터프레임의 행을 유지하고, 그렇지 않으면 삭제\n",
    "# info에 해당 id의 name 값이 있는지 확인\n",
    "valid_ids = info.loc[info[\"name\"].notna(), \"id\"]\n",
    "# mg_reviews에서 id가 valid_ids에 포함된 행만 유지\n",
    "filtered_reviews = mg_reviews[mg_reviews[\"id\"].isin(valid_ids)]\n",
    "print(filtered_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 91598 데이터 저장저장!! 완성 및 이름 변경 -> row_data/naver_store_reviews.csv\n",
    "filtered_reviews.to_csv(\"naver_store_reviews.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91598, 4)\n",
      "91598\n",
      "3559\n"
     ]
    }
   ],
   "source": [
    "# 확인\n",
    "reviews = pd.read_csv(\"naver_store_reviews.csv\")\n",
    "print(reviews.shape)\n",
    "print(sum(reviews[\"reviews\"].notna()))\n",
    "print(len(reviews[\"id\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
